{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Twitter Spam Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset - Social honeypot icwsm 2011"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!curl -O 'http://infolab.tamu.edu/static/users/kyumin/social_honeypot_icwsm_2011.zip'&& unzip social_honeypot_icwsm_2011.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.cross_validation import train_test_split, cross_val_score\n",
    "from sklearn import metrics\n",
    "from sklearn.calibration import calibration_curve\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "pd.set_option(\"display.max_columns\",101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Спамеры\n",
    "content_polluters = pd.read_table('./content_polluters.txt', header=None, names = [\n",
    "    \"UserID\",\n",
    "    \"ProfileCreatedAt\",\n",
    "    \"ProfileCollectedAt\",\n",
    "    \"NumberOfFollowings\",\n",
    "    \"NumberOfFollowers\",\n",
    "    \"NumberOfTweets\",\n",
    "    \"LengthOfScreenName\",\n",
    "    \"LengthOfDescriptionInUserProfile\"])\n",
    "content_polluters_tweets = pd.read_table('./content_polluters_tweets.txt', header=None, names = [\n",
    "    \"UserID\",\n",
    "    \"TweetID\",\n",
    "    \"Tweet\",\n",
    "    \"TweetCreatedAt\"\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Пользователь 1:1 Твит (последний по дате публикации)\n",
    "content_polluters = content_polluters.set_index(\"UserID\")\n",
    "content_polluters_tweets_distinct = content_polluters_tweets.sort_values('TweetCreatedAt', ascending = False).groupby(['UserID']).first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Легитимные пользователи\n",
    "legitimate_users = pd.read_table('./legitimate_users.txt', header=None, names = [\n",
    "    \"UserID\",\n",
    "    \"ProfileCreatedAt\",\n",
    "    \"ProfileCollectedAt\",\n",
    "    \"NumberOfFollowings\",\n",
    "    \"NumberOfFollowers\",\n",
    "    \"NumberOfTweets\",\n",
    "    \"LengthOfScreenName\",\n",
    "    \"LengthOfDescriptionInUserProfile\"])\n",
    "legitimate_users_tweets = pd.read_table('./legitimate_users_tweets.txt', header=None, names = [\n",
    "    \"UserID\",\n",
    "    \"TweetID\",\n",
    "    \"Tweet\",\n",
    "    \"TweetCreatedAt\"\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Пользователь 1:1 Твит (последний по дате публикации)\n",
    "legitimate_users = legitimate_users.set_index(\"UserID\")\n",
    "legitimate_users_tweets_distinct = legitimate_users_tweets.sort_values('TweetCreatedAt', ascending = False).groupby(['UserID']).first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "spammers = pd.concat([content_polluters, content_polluters_tweets_distinct], axis=1, join='inner')\n",
    "spammers['IsSpammer'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nonspammers =  pd.concat([legitimate_users, legitimate_users_tweets_distinct], axis=1, join='inner')\n",
    "nonspammers['IsSpammer'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open(\"blacklist.txt\", \"r\") as f:\n",
    "    spamwords=f.read().splitlines()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = pd.concat([spammers, nonspammers])\n",
    "data[\"ProfileCreatedAt\"] = pd.to_datetime(data[\"ProfileCreatedAt\"])\n",
    "data[\"TweetCreatedAt\"] = pd.to_datetime(data[\"TweetCreatedAt\"])\n",
    "data[\"ProfileCollectedAt\"] = pd.to_datetime(data[\"ProfileCollectedAt\"])\n",
    "data[\"Reputation\"] = data[\"NumberOfFollowers\"].divide((data[\"NumberOfFollowers\"] + data[\"NumberOfFollowings\"]), fill_value=True)\n",
    "data[\"AccountAge\"] = (data[\"ProfileCollectedAt\"] - data[\"ProfileCreatedAt\"]).astype('timedelta64[h]')\n",
    "data[\"Flwrs/Flwngs\"] = data[\"NumberOfFollowers\"].divide(data[\"NumberOfFollowings\"], fill_value=True)\n",
    "data[\"FlwngsIncrease\"] = data[\"NumberOfFollowings\"].divide(data[\"AccountAge\"])\n",
    "data[\"TweetsPerDay\"]  = data[\"NumberOfTweets\"].divide((data[\"AccountAge\"] / 24), fill_value=True)\n",
    "data[\"TweetsPerWeek\"]  = data[\"NumberOfTweets\"].divide((data[\"AccountAge\"] / (24 * 7)), fill_value=True)\n",
    "data[\"Tweet\"].str.extract('(http://\\S+|https://\\S+)', expand=True)\n",
    "data[\"Tweet\"].str.extract('(@\\S+)', expand=True)\n",
    "data[\"Tweet\"].str.extract('(#\\S+)', expand=True)\n",
    "data[\"NumberOfSpaces\"] = data[\"Tweet\"].str.count(' ')\n",
    "data[\"NumberOfWords\"] = data[\"Tweet\"].str.count(' ') + 1\n",
    "data[\"NumberOfSymbols\"] = data[\"Tweet\"].str.len()\n",
    "data[\"NumberOfQm\"] = data[\"Tweet\"].str.count('\\?')\n",
    "data[\"NumberOfEm\"] = data[\"Tweet\"].str.count('\\!')\n",
    "data[\"NumberOfURLs\"] = data[\"Tweet\"].str.count('(https://\\S+|http://\\S+)')\n",
    "data[\"NumberOfMentions\"] = data[\"Tweet\"].str.count('(@\\S+)')\n",
    "data[\"NumberOfHashtags\"] = data[\"Tweet\"].str.count('(#\\S+)')\n",
    "#data[\"NumberOfSpamWords\"] = data[\"Tweet\"].str.count('(' + '|'.join(spamwords) + ')')\n",
    "data.replace(np.inf, np.nan, inplace = True)\n",
    "data.fillna(0, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = (20,7)\n",
    "plt.rcParams['font.size'] = 25   \n",
    "\n",
    "data0=data[data.Reputation > .1]\n",
    "plt.hist([data0[data0.IsSpammer==1].Reputation.values,\n",
    "          data0[data0.IsSpammer==0].Reputation.values],label=[\"Спамер\",\"Легитимный пользователь\"],\n",
    "          alpha = .99)\n",
    "plt.legend()\n",
    "plt.xlabel(\"Репутация\")\n",
    "plt.ylabel(\"Количество пользователей\")\n",
    "plt.savefig(\"./pics/reputation.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "feature_cols = { \"UserFeatures\" : [\n",
    "                                \"LengthOfScreenName\",\n",
    "                                \"LengthOfDescriptionInUserProfile\",\n",
    "                                \"NumberOfFollowings\",\n",
    "                                \"NumberOfFollowers\",\n",
    "                                \"NumberOfTweets\",\n",
    "                                \"AccountAge\",\n",
    "                                \"Flwrs/Flwngs\",\n",
    "                                \"FlwngsIncrease\",\n",
    "                                \"TweetsPerDay\",\n",
    "                                \"TweetsPerWeek\"\n",
    "                                ],\n",
    "               \"ContentFeatures\":[ \n",
    "                                  \"NumberOfWords\",\n",
    "                                  \"NumberOfSymbols\",\n",
    "                                  \"NumberOfSpaces\",\n",
    "                                  \"NumberOfEm\",\n",
    "                                  \"NumberOfQm\",\n",
    "                                  \"NumberOfURLs\",\n",
    "                                  \"NumberOfHashtags\",\n",
    "                                  \"NumberOfMentions\"\n",
    "                                ],\n",
    " \n",
    "               }\n",
    "X = data[feature_cols[\"UserFeatures\"] + feature_cols[\"ContentFeatures\"]]\n",
    "Y = data['IsSpammer']\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, random_state = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def print_report(RealValues, PredictedValues ):\n",
    "    print('Accuracy: ' + str(metrics.accuracy_score(RealValues, PredictedValues)))\n",
    "    #print('\\n' + 'Classification report:')\n",
    "    #print(metrics.classification_report(RealValues, PredictedValues))\n",
    "    #print('\\n' + 'Confusion matrix: ')\n",
    "    #print(metrics.confusion_matrix(RealValues, PredictedValues))\n",
    "\n",
    "def print_cross_validation(model, X, Y):\n",
    "    scores = cross_val_score(model, X, Y, cv=10, scoring='accuracy')\n",
    "    #print(scores)\n",
    "    print('Cross Validation Score: ' + str(scores.mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for k in range(1,20, 2):\n",
    "    print(\"k = \" + str(k))\n",
    "    knn = KNeighborsClassifier(n_neighbors = k)\n",
    "    knn.fit(X_train, Y_train)\n",
    "    Y_pred = knn.predict(X_test)\n",
    "    print_report(Y_test, Y_pred)\n",
    "    print_cross_validation(knn, X, Y)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dt = DecisionTreeClassifier()\n",
    "dt.fit(X_train, Y_train)\n",
    "Y_pred = dt.predict(X_test)\n",
    "print_report(Y_test, Y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print_cross_validation(dt, X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = SelectFromModel(dt, prefit=True)\n",
    "X_new = model.transform(X_train)\n",
    "print(X_train.shape)\n",
    "print(X_new.shape)\n",
    "dt.fit(X_new, Y_train)\n",
    "Y_pred = dt.predict(X_test)\n",
    "print_report(Y_test, Y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bern = BernoulliNB()\n",
    "bern.fit(X_train, Y_train)\n",
    "Y_pred = bern.predict(X_test)\n",
    "print_report(Y_test, Y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print_cross_validation(bern, X, Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train[['NumberOfURLs','FlwngsIncrease','Flwrs/Flwngs','NumberOfFollowings']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from itertools import chain, combinations\n",
    "import copy\n",
    "\n",
    "best_score = -np.inf\n",
    "best_subset = None\n",
    "\n",
    "def combinations(target, data, X, y, estimator):\n",
    "    for i in range(len(data)):\n",
    "        new_target = copy.copy(target)\n",
    "        new_data = copy.copy(data)\n",
    "        new_target.append(data[i])\n",
    "        new_data = data[i+1:]\n",
    "        print(new_target)\n",
    "        \n",
    "        score = cross_val_score(estimator, X[:, list(new_target)], y, cv=cv).mean()\n",
    "        if score > best_score:\n",
    "            best_score, best_subset = score, new_target\n",
    "        combinations(new_target,\n",
    "                      new_data, X, y, estimator)\n",
    "        return best_subset, best_score\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "rfc = RandomForestClassifier()\n",
    "rfc.fit(X_train, Y_train)\n",
    "print(combinations([],X_train.columns, X_train, Y_train, rfc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "                      \n",
    "            \n",
    "target = []\n",
    "data = X.columns\n",
    " \n",
    "combinations(target,data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rfc = RandomForestClassifier()\n",
    "rfc.fit(X_train[['NumberOfURLs','FlwngsIncrease','Flwrs/Flwngs','NumberOfFollowings']], Y_train)\n",
    "Y_pred = rfc.predict(X_test[['NumberOfURLs','FlwngsIncrease','Flwrs/Flwngs','NumberOfFollowings']])\n",
    "print_report(Y_test, Y_pred)\n",
    "print_cross_validation(rfc, X, Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "ax1 = plt.subplot2grid((3, 1), (0, 0), rowspan=2)\n",
    "ax2 = plt.subplot2grid((3, 1), (2, 0))\n",
    "\n",
    "ax1.plot([0, 1], [0, 1], \"k:\", label=\"Perfectly calibrated\")\n",
    "for clf, name in [(knn, 'kNN'),\n",
    "                  (dt, 'Decision Tree'),\n",
    "                  (bern, 'Naive Bayes'),\n",
    "                  (rfc, 'Random Forest')]:\n",
    "    clf.fit(X_train, Y_train)\n",
    "    if hasattr(clf, \"predict_proba\"):\n",
    "        prob_pos = clf.predict_proba(X_test)[:, 1]\n",
    "    else:  # use decision function\n",
    "        prob_pos = clf.decision_function(X_test)\n",
    "        prob_pos = \\\n",
    "            (prob_pos - prob_pos.min()) / (prob_pos.max() - prob_pos.min())\n",
    "    fraction_of_positives, mean_predicted_value = \\\n",
    "        calibration_curve(Y_test, prob_pos, n_bins=10)\n",
    "\n",
    "    ax1.plot(mean_predicted_value, fraction_of_positives, \"s-\",\n",
    "             label=\"%s\" % (name, ))\n",
    "\n",
    "    ax2.hist(prob_pos, range=(0, 1), bins=10, label=name,\n",
    "             histtype=\"step\", lw=2)\n",
    "\n",
    "ax1.set_ylabel(\"Fraction of positives\")\n",
    "ax1.set_ylim([-0.05, 1.05])\n",
    "ax1.legend(loc=\"lower right\")\n",
    "ax1.set_title('Calibration plots  (reliability curve)')\n",
    "\n",
    "ax2.set_xlabel(\"Mean predicted value\")\n",
    "ax2.set_ylabel(\"Count\")\n",
    "ax2.legend(loc=\"upper center\", ncol=2)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#svm = SVC()\n",
    "#svm.fit(X_train, Y_train)\n",
    "#Y_pred = svm.predict(X_test)\n",
    "#print_report(Y_test, Y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#scores = cross_val_score(svm, X, Y, cv=10, scoring='accuracy')\n",
    "#print(scores)\n",
    "#print(scores.mean()) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
